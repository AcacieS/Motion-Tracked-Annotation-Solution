{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtufXocEA0t9",
        "outputId": "de002c79-1c3d-4086-cb25-1b9b24dde11c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Jan 18 16:43:31 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   51C    P8             11W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "Using GPU\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi\n",
        "\n",
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  print('Using GPU')\n",
        "  device = 'cuda'\n",
        "else:\n",
        "  print('CUDA not available. Please connect to a GPU instance if possible.')\n",
        "  device = 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQtM2nKLA3CF",
        "outputId": "2e29ba2e-afd8-44bf-91d6-182290315f39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Cutie'...\n",
            "remote: Enumerating objects: 609, done.\u001b[K\n",
            "remote: Counting objects: 100% (238/238), done.\u001b[K\n",
            "remote: Compressing objects: 100% (73/73), done.\u001b[K\n",
            "remote: Total 609 (delta 199), reused 165 (delta 165), pack-reused 371 (from 1)\u001b[K\n",
            "Receiving objects: 100% (609/609), 2.81 MiB | 2.44 MiB/s, done.\n",
            "Resolving deltas: 100% (308/308), done.\n",
            "/content/Cutie\n",
            "Obtaining file:///content/Cutie\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting thinplate@ git+https://github.com/cheind/py-thin-plate-spline (from cutie==1.0.0)\n",
            "  Cloning https://github.com/cheind/py-thin-plate-spline to /tmp/pip-install-rro8jjc3/thinplate_30b77c4a901e413aa604aa71e20cd9e1\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/cheind/py-thin-plate-spline /tmp/pip-install-rro8jjc3/thinplate_30b77c4a901e413aa604aa71e20cd9e1\n",
            "  Resolved https://github.com/cheind/py-thin-plate-spline to commit f6995795397118b7d0ac01aecd3f39ffbfad9dee\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting av>=0.5.2 (from cutie==1.0.0)\n",
            "  Downloading av-16.1.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (4.6 kB)\n",
            "Collecting cchardet>=2.1.7 (from cutie==1.0.0)\n",
            "  Downloading cchardet-2.1.7.tar.gz (653 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m653.6/653.6 kB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: charset-normalizer>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from cutie==1.0.0) (3.4.4)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.12/dist-packages (from cutie==1.0.0) (3.0.12)\n",
            "Requirement already satisfied: easydict in /usr/local/lib/python3.12/dist-packages (from cutie==1.0.0) (1.13)\n",
            "Requirement already satisfied: einops>=0.6 in /usr/local/lib/python3.12/dist-packages (from cutie==1.0.0) (0.8.1)\n",
            "Requirement already satisfied: gdown>=4.7.1 in /usr/local/lib/python3.12/dist-packages (from cutie==1.0.0) (5.2.0)\n",
            "Requirement already satisfied: gitpython>=3.1 in /usr/local/lib/python3.12/dist-packages (from cutie==1.0.0) (3.1.46)\n",
            "Requirement already satisfied: gradio>=3.34 in /usr/local/lib/python3.12/dist-packages (from cutie==1.0.0) (5.50.0)\n",
            "Collecting hickle>=5.0 (from cutie==1.0.0)\n",
            "  Downloading hickle-5.0.3-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting hydra-core>=1.3.2 (from cutie==1.0.0)\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting netifaces>=0.11.0 (from cutie==1.0.0)\n",
            "  Downloading netifaces-0.11.0.tar.gz (30 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.12/dist-packages (from cutie==1.0.0) (2.0.2)\n",
            "Requirement already satisfied: opencv-python>=4.8 in /usr/local/lib/python3.12/dist-packages (from cutie==1.0.0) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=9.5 in /usr/local/lib/python3.12/dist-packages (from cutie==1.0.0) (11.3.0)\n",
            "Requirement already satisfied: pycocotools>=2.0.7 in /usr/local/lib/python3.12/dist-packages (from cutie==1.0.0) (2.0.11)\n",
            "Collecting pyqtdarktheme (from cutie==1.0.0)\n",
            "  Downloading PyQtDarkTheme-0.1.7-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting pyside6>=6.2.0 (from cutie==1.0.0)\n",
            "  Downloading pyside6-6.10.1-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from cutie==1.0.0) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.12/dist-packages (from cutie==1.0.0) (1.16.3)\n",
            "Requirement already satisfied: tensorboard>=2.11 in /usr/local/lib/python3.12/dist-packages (from cutie==1.0.0) (2.19.0)\n",
            "Requirement already satisfied: tqdm>=4.66.1 in /usr/local/lib/python3.12/dist-packages (from cutie==1.0.0) (4.67.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown>=4.7.1->cutie==1.0.0) (4.13.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from gdown>=4.7.1->cutie==1.0.0) (3.20.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython>=3.1->cutie==1.0.0) (4.0.12)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio>=3.34->cutie==1.0.0) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio>=3.34->cutie==1.0.0) (4.12.1)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio>=3.34->cutie==1.0.0) (1.2.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio>=3.34->cutie==1.0.0) (0.123.10)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio>=3.34->cutie==1.0.0) (1.0.0)\n",
            "Requirement already satisfied: gradio-client==1.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio>=3.34->cutie==1.0.0) (1.14.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio>=3.34->cutie==1.0.0) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio>=3.34->cutie==1.0.0) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio>=3.34->cutie==1.0.0) (0.36.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio>=3.34->cutie==1.0.0) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio>=3.34->cutie==1.0.0) (3.0.3)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio>=3.34->cutie==1.0.0) (3.11.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio>=3.34->cutie==1.0.0) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio>=3.34->cutie==1.0.0) (2.2.2)\n",
            "Requirement already satisfied: pydantic<=2.12.3,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio>=3.34->cutie==1.0.0) (2.12.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio>=3.34->cutie==1.0.0) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio>=3.34->cutie==1.0.0) (0.0.21)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio>=3.34->cutie==1.0.0) (6.0.3)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio>=3.34->cutie==1.0.0) (0.14.11)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio>=3.34->cutie==1.0.0) (0.1.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio>=3.34->cutie==1.0.0) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio>=3.34->cutie==1.0.0) (0.50.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio>=3.34->cutie==1.0.0) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio>=3.34->cutie==1.0.0) (0.21.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio>=3.34->cutie==1.0.0) (4.15.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio>=3.34->cutie==1.0.0) (0.40.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.14.0->gradio>=3.34->cutie==1.0.0) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=13.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.14.0->gradio>=3.34->cutie==1.0.0) (15.0.1)\n",
            "Requirement already satisfied: h5py>=2.10.0 in /usr/local/lib/python3.12/dist-packages (from hickle>=5.0->cutie==1.0.0) (3.15.1)\n",
            "Requirement already satisfied: omegaconf<2.4,>=2.2 in /usr/local/lib/python3.12/dist-packages (from hydra-core>=1.3.2->cutie==1.0.0) (2.3.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.12/dist-packages (from hydra-core>=1.3.2->cutie==1.0.0) (4.9.3)\n",
            "Collecting shiboken6==6.10.1 (from pyside6>=6.2.0->cutie==1.0.0)\n",
            "  Downloading shiboken6-6.10.1-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (2.5 kB)\n",
            "Collecting PySide6_Essentials==6.10.1 (from pyside6>=6.2.0->cutie==1.0.0)\n",
            "  Downloading pyside6_essentials-6.10.1-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (3.7 kB)\n",
            "Collecting PySide6_Addons==6.10.1 (from pyside6>=6.2.0->cutie==1.0.0)\n",
            "  Downloading pyside6_addons-6.10.1-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.11->cutie==1.0.0) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.11->cutie==1.0.0) (1.76.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.11->cutie==1.0.0) (3.10)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.11->cutie==1.0.0) (5.29.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.11->cutie==1.0.0) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.11->cutie==1.0.0) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.11->cutie==1.0.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.11->cutie==1.0.0) (3.1.5)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->cutie==1.0.0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->cutie==1.0.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->cutie==1.0.0) (2026.1.4)\n",
            "Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from thinplate@ git+https://github.com/cheind/py-thin-plate-spline->cutie==1.0.0) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from thinplate@ git+https://github.com/cheind/py-thin-plate-spline->cutie==1.0.0) (0.24.0+cu126)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi<1.0,>=0.115.2->gradio>=3.34->cutie==1.0.0) (0.0.4)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython>=3.1->cutie==1.0.0) (5.0.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio>=3.34->cutie==1.0.0) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio>=3.34->cutie==1.0.0) (0.16.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio>=3.34->cutie==1.0.0) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio>=3.34->cutie==1.0.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio>=3.34->cutie==1.0.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio>=3.34->cutie==1.0.0) (2025.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio>=3.34->cutie==1.0.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio>=3.34->cutie==1.0.0) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio>=3.34->cutie==1.0.0) (0.4.2)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->thinplate@ git+https://github.com/cheind/py-thin-plate-spline->cutie==1.0.0) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->thinplate@ git+https://github.com/cheind/py-thin-plate-spline->cutie==1.0.0) (3.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->thinplate@ git+https://github.com/cheind/py-thin-plate-spline->cutie==1.0.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->thinplate@ git+https://github.com/cheind/py-thin-plate-spline->cutie==1.0.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->thinplate@ git+https://github.com/cheind/py-thin-plate-spline->cutie==1.0.0) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->thinplate@ git+https://github.com/cheind/py-thin-plate-spline->cutie==1.0.0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->thinplate@ git+https://github.com/cheind/py-thin-plate-spline->cutie==1.0.0) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->thinplate@ git+https://github.com/cheind/py-thin-plate-spline->cutie==1.0.0) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->thinplate@ git+https://github.com/cheind/py-thin-plate-spline->cutie==1.0.0) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->thinplate@ git+https://github.com/cheind/py-thin-plate-spline->cutie==1.0.0) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->thinplate@ git+https://github.com/cheind/py-thin-plate-spline->cutie==1.0.0) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->thinplate@ git+https://github.com/cheind/py-thin-plate-spline->cutie==1.0.0) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->thinplate@ git+https://github.com/cheind/py-thin-plate-spline->cutie==1.0.0) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->thinplate@ git+https://github.com/cheind/py-thin-plate-spline->cutie==1.0.0) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->thinplate@ git+https://github.com/cheind/py-thin-plate-spline->cutie==1.0.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->thinplate@ git+https://github.com/cheind/py-thin-plate-spline->cutie==1.0.0) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->thinplate@ git+https://github.com/cheind/py-thin-plate-spline->cutie==1.0.0) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=0.4.0->thinplate@ git+https://github.com/cheind/py-thin-plate-spline->cutie==1.0.0) (3.5.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio>=3.34->cutie==1.0.0) (8.3.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio>=3.34->cutie==1.0.0) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio>=3.34->cutie==1.0.0) (13.9.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown>=4.7.1->cutie==1.0.0) (2.8.1)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown>=4.7.1->cutie==1.0.0) (1.7.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio>=3.34->cutie==1.0.0) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio>=3.34->cutie==1.0.0) (2.19.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=0.4.0->thinplate@ git+https://github.com/cheind/py-thin-plate-spline->cutie==1.0.0) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio>=3.34->cutie==1.0.0) (0.1.2)\n",
            "Downloading av-16.1.0-cp312-cp312-manylinux_2_28_x86_64.whl (41.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hickle-5.0.3-py3-none-any.whl (107 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyside6-6.10.1-cp39-abi3-manylinux_2_34_x86_64.whl (557 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.8/557.8 kB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyside6_addons-6.10.1-cp39-abi3-manylinux_2_34_x86_64.whl (170.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.7/170.7 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyside6_essentials-6.10.1-cp39-abi3-manylinux_2_34_x86_64.whl (76.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.8/76.8 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading shiboken6-6.10.1-cp39-abi3-manylinux_2_34_x86_64.whl (271 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m272.0/272.0 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyQtDarkTheme-0.1.7-py3-none-any.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.6/99.6 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: cutie, cchardet, netifaces, thinplate\n",
            "  Building editable for cutie (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cutie: filename=cutie-1.0.0-py3-none-any.whl size=4557 sha256=b2ff65de2832e544a88c7d2ce97243de1eefac2b88fbcba8ccaad1a25665908d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-zk8r915l/wheels/54/98/40/fc7af58c732d3bdcd8fcd7a553a972f7cc75b4be607742991e\n",
            "  Building wheel for cchardet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cchardet: filename=cchardet-2.1.7-cp312-cp312-linux_x86_64.whl size=300363 sha256=02232c1de13908a0c028ca11da980a14c8e08f4484708d5277a4adc10430621e\n",
            "  Stored in directory: /root/.cache/pip/wheels/e4/40/3c/290a62e1fa01b0c46e93720c12eb1e97028f81ff04368b6b56\n",
            "  Building wheel for netifaces (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for netifaces: filename=netifaces-0.11.0-cp312-cp312-linux_x86_64.whl size=36189 sha256=43a1fe71a7460bac9985f03fc614f59446de04953b7479b0e0a866f7cea058b4\n",
            "  Stored in directory: /root/.cache/pip/wheels/63/fa/57/da80d0ffc8f993315c479b7cd4c8fb1c23910c8baccf6b1b27\n",
            "  Building wheel for thinplate (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for thinplate: filename=thinplate-1.0.0-py3-none-any.whl size=6701 sha256=0a3d69d76d99c59343b711cd8e76bd4d24cb1e194fd41c0854bc976643eba8c8\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-zk8r915l/wheels/65/b2/ff/baba3d814b978be1f20df5b7a642a341d0e8ebafd1ea260718\n",
            "Successfully built cutie cchardet netifaces thinplate\n",
            "Installing collected packages: netifaces, cchardet, shiboken6, pyqtdarktheme, av, PySide6_Essentials, hydra-core, hickle, PySide6_Addons, pyside6, thinplate, cutie\n",
            "Successfully installed PySide6_Addons-6.10.1 PySide6_Essentials-6.10.1 av-16.1.0 cchardet-2.1.7 cutie-1.0.0 hickle-5.0.3 hydra-core-1.3.2 netifaces-0.11.0 pyqtdarktheme-0.1.7 pyside6-6.10.1 shiboken6-6.10.1 thinplate-1.0.0\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/hkchengrex/Cutie.git\n",
        "%cd Cutie\n",
        "#%git\n",
        "!pip install -e ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_qIRplQjA42u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10948b12-f933-4af1-853b-da62b475ccb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading coco_lvis_h18_itermask.pth to /content/Cutie/cutie/utils/../../weights...\n",
            "100% 40.7M/40.7M [00:02<00:00, 19.0MiB/s]\n",
            "Downloading cutie-base-mega.pth to /content/Cutie/cutie/utils/../../weights...\n",
            "100% 140M/140M [00:03<00:00, 37.2MiB/s]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!python cutie/utils/download_models.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4qQmqJ-3t13",
        "outputId": "f91e36f3-bb42-4d14-ec15-867eb039426d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: hydra-core in /usr/local/lib/python3.12/dist-packages (1.3.2)\n",
            "Requirement already satisfied: omegaconf in /usr/local/lib/python3.12/dist-packages (2.3.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.50.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.12/dist-packages (from hydra-core) (4.9.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from hydra-core) (25.0)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.12/dist-packages (from omegaconf) (6.0.3)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.12.1)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.2.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.123.10)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (1.0.0)\n",
            "Requirement already satisfied: gradio-client==1.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.14.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.36.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.3)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.5)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pydantic<=2.12.3,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.12.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.21)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.14.11)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.50.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.21.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.15.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.40.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.14.0->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=13.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.14.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.11)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi<1.0,>=0.115.2->gradio) (0.0.4)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.20.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.12.3,>=2.0->gradio) (0.4.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.3.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (2.5.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install hydra-core omegaconf opencv-python pillow gradio numpy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgKoWLWxA79e",
        "outputId": "028b4000-f81a-4a24-d827-c52132285d27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 270MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 277MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUTIE loaded OK: /content/Cutie/weights/cutie-base-mega.pth | device: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from pathlib import Path\n",
        "from omegaconf import open_dict\n",
        "from hydra import compose, initialize_config_dir\n",
        "from hydra.core.global_hydra import GlobalHydra\n",
        "\n",
        "from cutie.model.cutie import CUTIE\n",
        "from cutie.inference.utils.args_utils import get_dataset_cfg\n",
        "\n",
        "# ---- choose device ----\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "# DEVICE = \"cpu\"\n",
        "\n",
        "# ---- clear hydra (notebook) ----\n",
        "if GlobalHydra.instance().is_initialized():\n",
        "    GlobalHydra.instance().clear()\n",
        "\n",
        "# ---- Colab-compatible absolute paths ----\n",
        "PROJECT_ROOT = Path(\"/content/Cutie\").resolve()          # 你的 repo 在 colab 的位置\n",
        "CONFIG_DIR   = (PROJECT_ROOT / \"cutie/config\").resolve()      # 对应原来的 D:\\...\\cutie\\config\n",
        "WEIGHTS_PATH = (PROJECT_ROOT / \"weights\" / \"cutie-base-mega.pth\").resolve()\n",
        "\n",
        "with torch.inference_mode():\n",
        "    initialize_config_dir(\n",
        "        version_base=\"1.3.2\",\n",
        "        config_dir=str(CONFIG_DIR),   # 关键：绝对路径 + str\n",
        "        job_name=\"eval_config\",\n",
        "    )\n",
        "    cfg = compose(config_name=\"eval_config\")\n",
        "\n",
        "    with open_dict(cfg):\n",
        "        cfg[\"weights\"] = str(WEIGHTS_PATH)  # 关键：colab 路径\n",
        "        if cfg.get(\"mem_every\", None) is None:\n",
        "            cfg[\"mem_every\"] = 5\n",
        "        if cfg.get(\"stagger_updates\", None) is None:\n",
        "            cfg[\"stagger_updates\"] = 0\n",
        "\n",
        "    _ = get_dataset_cfg(cfg)\n",
        "\n",
        "    cutie = CUTIE(cfg).to(DEVICE).eval()\n",
        "    model_weights = torch.load(cfg.weights, map_location=DEVICE)\n",
        "    cutie.load_weights(model_weights)\n",
        "\n",
        "print(\"CUTIE loaded OK:\", cfg.weights, \"| device:\", DEVICE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "osSkA29oA8vw",
        "outputId": "ad9d9679-2497-4c57-8e6f-8e235127e81b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://dd9bfd8de8b1cfc3e9.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://dd9bfd8de8b1cfc3e9.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:    Exception in ASGI application\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/protocols/http/httptools_impl.py\", line 416, in run_asgi\n",
            "    result = await app(  # type: ignore[func-returns-value]\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/uvicorn/middleware/proxy_headers.py\", line 60, in __call__\n",
            "    return await self.app(scope, receive, send)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/applications.py\", line 1139, in __call__\n",
            "    await super().__call__(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/applications.py\", line 107, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/errors.py\", line 186, in __call__\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/errors.py\", line 164, in __call__\n",
            "    await self.app(scope, receive, _send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/brotli_middleware.py\", line 74, in __call__\n",
            "    return await self.app(scope, receive, send)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/route_utils.py\", line 882, in __call__\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/middleware/exceptions.py\", line 63, in __call__\n",
            "    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
            "    await app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/middleware/asyncexitstack.py\", line 18, in __call__\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 716, in __call__\n",
            "    await self.middleware_stack(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 736, in app\n",
            "    await route.handle(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/routing.py\", line 290, in handle\n",
            "    await self.app(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 119, in app\n",
            "    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n",
            "    raise exc\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n",
            "    await app(scope, receive, sender)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 105, in app\n",
            "    response = await f(request)\n",
            "               ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 385, in app\n",
            "    raw_response = await run_endpoint_function(\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/fastapi/routing.py\", line 284, in run_endpoint_function\n",
            "    return await dependant.call(**values)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/routes.py\", line 1671, in get_upload_progress\n",
            "    await asyncio.wait_for(\n",
            "  File \"/usr/lib/python3.12/asyncio/tasks.py\", line 520, in wait_for\n",
            "    return await fut\n",
            "           ^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/gradio/route_utils.py\", line 528, in is_tracked\n",
            "    return await self._signals[upload_id].wait()\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/asyncio/locks.py\", line 209, in wait\n",
            "    fut = self._get_loop().create_future()\n",
            "          ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/asyncio/mixins.py\", line 20, in _get_loop\n",
            "    raise RuntimeError(f'{self!r} is bound to a different event loop')\n",
            "RuntimeError: <asyncio.locks.Event object at 0x7871fcc5c710 [unset]> is bound to a different event loop\n",
            "/content/Cutie/cutie/utils/tensor_utils.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=False):\n",
            "/content/Cutie/cutie/model/modules.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=False):\n",
            "/content/Cutie/cutie/model/transformer/object_summarizer.py:78: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=False):\n",
            "/content/Cutie/cutie/model/big_modules.py:289: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=False):\n",
            "/content/Cutie/cutie/model/modules.py:62: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=False):\n",
            "/usr/local/lib/python3.12/dist-packages/gradio/components/video.py:398: UserWarning: Video does not have browser-compatible container or codec. Converting to mp4.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import os, cv2, tempfile\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import gradio as gr\n",
        "from omegaconf import open_dict\n",
        "import time\n",
        "\n",
        "\n",
        "OUT_DIR = os.path.join(tempfile.gettempdir(), \"cutie_gradio\")\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "import traceback\n",
        "from cutie.inference.inference_core import InferenceCore\n",
        "from gui.interactive_utils import image_to_torch, torch_prob_to_numpy_mask, index_numpy_to_one_hot_torch, overlay_davis\n",
        "\n",
        "DEFAULT_VIDEO = \"Lapchole4.mp4\"\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "def _resolve_video_path(p):\n",
        "    # cand = [p, os.path.join(\"/content\", p)]\n",
        "    cand = [p, os.path.join(os.getcwd(), p)]\n",
        "    for c in cand:\n",
        "        if c and os.path.exists(c):\n",
        "            return c\n",
        "    raise gr.Error(f\"Video not found: {p}\")\n",
        "\n",
        "def _get_video_info(video_path):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        raise gr.Error(f\"Cannot open video: {video_path}\")\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    fps = 30.0 if (fps is None or fps <= 1e-3) else float(fps)\n",
        "    n = int(cap.get(cv2.CAP_PROP_FRAME_COUNT) or 0)\n",
        "    w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH) or 0)\n",
        "    h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT) or 0)\n",
        "    cap.release()\n",
        "    return fps, n, w, h\n",
        "\n",
        "def _read_frame(video_path, frame_idx):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        raise gr.Error(f\"Cannot open video: {video_path}\")\n",
        "    cap.set(cv2.CAP_PROP_POS_FRAMES, int(frame_idx))\n",
        "    ok, frame = cap.read()\n",
        "    cap.release()\n",
        "    if (not ok) or frame is None:\n",
        "        raise gr.Error(f\"Failed to read frame {frame_idx}\")\n",
        "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    return frame, Image.fromarray(frame_rgb)\n",
        "\n",
        "def _editor_value_from_frame(frame_pil):\n",
        "    # 关键：让你“在这一帧上画”，不是黑底\n",
        "    # ImageEditor 需要 composite 字段，否则你之前会 KeyError\n",
        "    return {\"background\": frame_pil, \"layers\": [], \"composite\": frame_pil}\n",
        "\n",
        "def _mask_from_editor(editor_value):\n",
        "    \"\"\"\n",
        "    从 ImageEditor 取 mask：用 composite 和 background 的像素差分得到前景区域\n",
        "    你在帧上画的地方会改变 composite 像素 -> diff>阈值 -> mask=1\n",
        "    \"\"\"\n",
        "    if editor_value is None:\n",
        "        raise gr.Error(\"Mask editor is empty. Please paint on the frame.\")\n",
        "    bg = editor_value.get(\"background\", None)\n",
        "    comp = editor_value.get(\"composite\", None) or bg\n",
        "    if bg is None or comp is None:\n",
        "        raise gr.Error(\"ImageEditor returned no background/composite.\")\n",
        "\n",
        "    bg = bg.convert(\"RGB\")\n",
        "    comp = comp.convert(\"RGB\")\n",
        "    bg_arr = np.array(bg).astype(np.int16)\n",
        "    cp_arr = np.array(comp).astype(np.int16)\n",
        "\n",
        "    if bg_arr.shape != cp_arr.shape:\n",
        "        raise gr.Error(\"Editor output size mismatch. Try reloading the frame.\")\n",
        "\n",
        "    diff = np.abs(cp_arr - bg_arr).sum(axis=-1)  # H,W\n",
        "    mask = (diff > 25).astype(np.uint8)          # 阈值可调：越大越不敏感\n",
        "    return mask\n",
        "\n",
        "def _save_overlay_video(frames_bgr, fps, out_mp4):\n",
        "    h, w = frames_bgr[0].shape[:2]\n",
        "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
        "    vw = cv2.VideoWriter(out_mp4, fourcc, fps, (w, h))\n",
        "    for f in frames_bgr:\n",
        "        vw.write(f)\n",
        "    vw.release()\n",
        "\n",
        "\n",
        "def load_video(video_path_str):\n",
        "    vp = _resolve_video_path(video_path_str)\n",
        "    fps, n, w, h = _get_video_info(vp)\n",
        "    _, frame0_pil = _read_frame(vp, 0)\n",
        "    editor_init = _editor_value_from_frame(frame0_pil)\n",
        "\n",
        "    info = f\"Loaded: {vp} | frames={n} | fps={fps:.2f} | size={w}x{h}\"\n",
        "\n",
        "    # 选帧 slider：0..n-1\n",
        "    frame_idx_update = gr.update(minimum=0, maximum=max(0, n-1), value=0, step=1)\n",
        "\n",
        "    # frames_to_propagate 上限：n-1-当前帧（当前帧=0）\n",
        "    max_prop = max(1, (n - 1) - 0)\n",
        "    frames_to_prop_update = gr.update(minimum=1, maximum=max_prop, value=min(200, max_prop), step=1)\n",
        "\n",
        "    # max_internal_size：建议不超过 max(w,h)，越小越快越糊\n",
        "    max_side = max(w, h)\n",
        "    default_mis = min(max_side, 400)          # <<< changed: default to 400\n",
        "    default_mis = max(256, default_mis)\n",
        "    max_internal_update = gr.update(minimum=256, maximum=max(256, max_side), value=default_mis, step=32)\n",
        "\n",
        "    return vp, frame0_pil, editor_init, frame_idx_update, frames_to_prop_update, max_internal_update, info\n",
        "\n",
        "\n",
        "def overlay_fast_bgr(frame_bgr, mask01, color_bgr=(0, 255, 0), alpha=0.45, draw_outline=True):\n",
        "    \"\"\"\n",
        "    frame_bgr: HxWx3 uint8 (OpenCV BGR)\n",
        "    mask01:    HxW, 0/1 uint8 (or bool)\n",
        "    return:    HxWx3 uint8 BGR\n",
        "    \"\"\"\n",
        "    if mask01 is None:\n",
        "        return frame_bgr\n",
        "    m = (mask01 > 0)\n",
        "    if not m.any():\n",
        "        return frame_bgr  # 没有前景就原样返回（不要报错/不要花时间）\n",
        "\n",
        "    out = frame_bgr.copy()\n",
        "\n",
        "    # 只对 mask 区域做 alpha blend（避免生成整张 color layer）\n",
        "    # out[m] = (1-a)*frame + a*color\n",
        "    a = float(alpha)\n",
        "    inv = 1.0 - a\n",
        "    c0, c1, c2 = map(float, color_bgr)  # B,G,R\n",
        "    region = out[m].astype(np.float32)\n",
        "    region[:, 0] = region[:, 0] * inv + c0 * a\n",
        "    region[:, 1] = region[:, 1] * inv + c1 * a\n",
        "    region[:, 2] = region[:, 2] * inv + c2 * a\n",
        "    out[m] = region.astype(np.uint8)\n",
        "\n",
        "    if draw_outline:\n",
        "        # 画一圈轮廓（很便宜，但可视效果提升大）\n",
        "        mu8 = (m.astype(np.uint8) * 255)\n",
        "        contours, _ = cv2.findContours(mu8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        if contours:\n",
        "            cv2.drawContours(out, contours, -1, (0, 0, 255), 2)  # 红色边\n",
        "\n",
        "    return out\n",
        "\n",
        "\n",
        "\n",
        "def _estimate_affine_lk(prev_bgr, curr_bgr, prev_mask01,\n",
        "                        max_corners=400,\n",
        "                        quality=0.01,\n",
        "                        min_dist=7,\n",
        "                        ransac_thresh=3.0,\n",
        "                        lk_scale=0.5,          # <<< 新增：LK 用的缩放比例(0<scale<=1)，0.5 很常用\n",
        "                        win_size=21,\n",
        "                        max_level=3):\n",
        "    \"\"\"\n",
        "    低分辨率 LK + 仿射估计（返回原始分辨率坐标系的 M）\n",
        "\n",
        "    prev_mask01: HxW, 0/1 uint8\n",
        "    返回: (M, inlier_ratio, n_good)\n",
        "      M: 2x3 仿射矩阵 (用于原尺寸 warpAffine) or None\n",
        "    \"\"\"\n",
        "    import cv2\n",
        "    import numpy as np\n",
        "\n",
        "    # --- safety ---\n",
        "    s = float(lk_scale)\n",
        "    if not (0.0 < s <= 1.0):\n",
        "        s = 0.5\n",
        "\n",
        "    # --- grayscale ---\n",
        "    prev_gray = cv2.cvtColor(prev_bgr, cv2.COLOR_BGR2GRAY)\n",
        "    curr_gray = cv2.cvtColor(curr_bgr, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    h, w = prev_gray.shape[:2]\n",
        "\n",
        "    # --- downscale for LK ---\n",
        "    if s < 1.0:\n",
        "        new_w = max(32, int(w * s))\n",
        "        new_h = max(32, int(h * s))\n",
        "        prev_s = cv2.resize(prev_gray, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
        "        curr_s = cv2.resize(curr_gray, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
        "\n",
        "        # mask 缩放用最近邻，保持 0/1\n",
        "        mask_u8 = (prev_mask01 > 0).astype(np.uint8) * 255\n",
        "        mask_s = cv2.resize(mask_u8, (new_w, new_h), interpolation=cv2.INTER_NEAREST)\n",
        "    else:\n",
        "        prev_s, curr_s = prev_gray, curr_gray\n",
        "        mask_s = (prev_mask01 > 0).astype(np.uint8) * 255\n",
        "\n",
        "    # --- scale params for small image (optional but helps stability) ---\n",
        "    # min_dist / blockSize 在小图上也应该缩放\n",
        "    min_dist_s = max(1, int(min_dist * s)) if s < 1.0 else int(min_dist)\n",
        "    block_s = 7\n",
        "    if s < 1.0:\n",
        "        block_s = max(3, int(7 * s))\n",
        "        if block_s % 2 == 0:\n",
        "            block_s += 1\n",
        "\n",
        "    # --- 1) find corners on small image (prefer mask region) ---\n",
        "    pts0 = cv2.goodFeaturesToTrack(\n",
        "        prev_s, maxCorners=max_corners,\n",
        "        qualityLevel=quality, minDistance=min_dist_s,\n",
        "        blockSize=block_s, mask=mask_s\n",
        "    )\n",
        "    # fallback to full small image (still cheap)\n",
        "    if pts0 is None or len(pts0) < 8:\n",
        "        pts0 = cv2.goodFeaturesToTrack(\n",
        "            prev_s, maxCorners=max_corners,\n",
        "            qualityLevel=quality, minDistance=min_dist_s,\n",
        "            blockSize=block_s, mask=None\n",
        "        )\n",
        "\n",
        "    if pts0 is None or len(pts0) < 8:\n",
        "        return None, 0.0, 0\n",
        "\n",
        "    # --- 2) LK flow on small image ---\n",
        "    pts1, st, err = cv2.calcOpticalFlowPyrLK(\n",
        "        prev_s, curr_s, pts0, None,\n",
        "        winSize=(int(win_size), int(win_size)),\n",
        "        maxLevel=int(max_level),\n",
        "        criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 30, 0.01)\n",
        "    )\n",
        "\n",
        "    st = st.reshape(-1)\n",
        "    good0 = pts0.reshape(-1, 2)[st == 1]\n",
        "    good1 = pts1.reshape(-1, 2)[st == 1]\n",
        "\n",
        "    if good0.shape[0] < 8:\n",
        "        return None, 0.0, int(good0.shape[0])\n",
        "\n",
        "    # --- 3) map points back to original resolution coords ---\n",
        "    if s < 1.0:\n",
        "        inv = 1.0 / s\n",
        "        good0 = good0 * inv\n",
        "        good1 = good1 * inv\n",
        "\n",
        "    # --- 4) affine with RANSAC (in original coords) ---\n",
        "    M, inliers = cv2.estimateAffinePartial2D(\n",
        "        good0, good1,\n",
        "        method=cv2.RANSAC,\n",
        "        ransacReprojThreshold=float(ransac_thresh),\n",
        "        maxIters=2000, confidence=0.99, refineIters=10\n",
        "    )\n",
        "    if M is None or inliers is None:\n",
        "        return None, 0.0, int(good0.shape[0])\n",
        "\n",
        "    inlier_ratio = float(inliers.sum()) / max(1, len(inliers))\n",
        "    return M, inlier_ratio, int(good0.shape[0])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def show_frame(video_path_str, frame_idx):\n",
        "    vp = _resolve_video_path(video_path_str)\n",
        "    fps, n, w, h = _get_video_info(vp)\n",
        "\n",
        "    frame_idx = int(frame_idx)\n",
        "    _, frame_pil = _read_frame(vp, frame_idx)\n",
        "\n",
        "    # 切到该帧时，frames_to_propagate 上限跟着变：n-1-当前帧\n",
        "    max_prop = max(1, (n - 1) - frame_idx)\n",
        "    frames_to_prop_update = gr.update(minimum=1, maximum=max_prop, value=min(200, max_prop), step=1)\n",
        "\n",
        "    return frame_pil, _editor_value_from_frame(frame_pil), frames_to_prop_update\n",
        "\n",
        "def run_track(video_path_str, start_frame_idx, editor_value, frames_to_propagate, max_internal_size,\n",
        "              lk_every, lk_corners, lk_inlier):\n",
        "    \"\"\"\n",
        "    Anchor-based design (your idea) + ROI (added):\n",
        "    - CUTIE runs ONLY on anchor frames: every K (=lk_every) frames.\n",
        "      (Except the first frame uses user mask to initialize.)\n",
        "    - CUTIE runs on a FIXED-SIZE ROI crop (square). ROI follows the object center estimated from masks.\n",
        "      This keeps CUTIE input resolution smaller and *constant*, which is safer for InferenceCore's memory.\n",
        "    - Between two CUTIE anchors, use LK affine warps:\n",
        "        * forward warp from prev anchor to intermediate frames\n",
        "        * backward warp from next anchor to intermediate frames\n",
        "        * blend the two warped masks (linear weight by position)\n",
        "    - LK is computed only in a window around the mask (big speed-up for LK).\n",
        "    - Overlay is FAST OpenCV alpha-blend (+ optional contour), no overlay_davis.\n",
        "    - Keeps full timing breakdown.\n",
        "    \"\"\"\n",
        "    import time\n",
        "    import numpy as np\n",
        "    import cv2\n",
        "    import torch\n",
        "    import gradio as gr\n",
        "    from omegaconf import open_dict\n",
        "\n",
        "    # -------------------------\n",
        "    # fast overlay (BGR)\n",
        "    # -------------------------\n",
        "    def overlay_fast_bgr(frame_bgr, mask01, color_bgr=(0, 255, 0), alpha=0.45, draw_outline=True):\n",
        "        if mask01 is None:\n",
        "            return frame_bgr\n",
        "        m = (mask01 > 0)\n",
        "        if not m.any():\n",
        "            return frame_bgr\n",
        "\n",
        "        out = frame_bgr.copy()\n",
        "        a = float(alpha)\n",
        "        inv = 1.0 - a\n",
        "        c0, c1, c2 = map(float, color_bgr)  # B,G,R\n",
        "\n",
        "        region = out[m].astype(np.float32)\n",
        "        region[:, 0] = region[:, 0] * inv + c0 * a\n",
        "        region[:, 1] = region[:, 1] * inv + c1 * a\n",
        "        region[:, 2] = region[:, 2] * inv + c2 * a\n",
        "        out[m] = region.astype(np.uint8)\n",
        "\n",
        "        if draw_outline:\n",
        "            mu8 = (m.astype(np.uint8) * 255)\n",
        "            contours, _ = cv2.findContours(mu8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "            if contours:\n",
        "                cv2.drawContours(out, contours, -1, (0, 0, 255), 2)  # red outline\n",
        "        return out\n",
        "\n",
        "    # -------------------------\n",
        "    # parse params\n",
        "    # -------------------------\n",
        "    K = int(lk_every)\n",
        "    lk_corners = int(lk_corners)\n",
        "    lk_inlier = float(lk_inlier)\n",
        "    if K < 1:\n",
        "        K = 1\n",
        "\n",
        "    vp = _resolve_video_path(video_path_str)\n",
        "    fps, n, w, h = _get_video_info(vp)\n",
        "\n",
        "    start_frame_idx = int(start_frame_idx)\n",
        "    frames_to_propagate = int(frames_to_propagate)\n",
        "    max_internal_size = int(max_internal_size)\n",
        "\n",
        "    remaining = (n - 1) - start_frame_idx\n",
        "    if remaining <= 0:\n",
        "        raise gr.Error(f\"No remaining frames from start_frame={start_frame_idx}. video_frames={n}\")\n",
        "    frames_to_propagate = max(1, min(frames_to_propagate, remaining))\n",
        "\n",
        "    # user mask (full-res)\n",
        "    mask_index = _mask_from_editor(editor_value)\n",
        "    if mask_index.sum() < 10:\n",
        "        raise gr.Error(\"Mask too small / empty. Please paint a larger region on the frame.\")\n",
        "    if mask_index.shape[0] != h or mask_index.shape[1] != w:\n",
        "        mask_index = cv2.resize(mask_index, (w, h), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "    # set cfg\n",
        "    with open_dict(cfg):\n",
        "        cfg[\"max_internal_size\"] = max_internal_size\n",
        "\n",
        "    processor = InferenceCore(cutie, cfg=cfg)\n",
        "\n",
        "    cap = cv2.VideoCapture(vp)\n",
        "    if not cap.isOpened():\n",
        "        raise gr.Error(f\"Cannot open video: {vp}\")\n",
        "    cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame_idx)\n",
        "\n",
        "    overlay_frames_bgr = []\n",
        "\n",
        "    # stats\n",
        "    model_calls = 0\n",
        "    lk_pairs = 0\n",
        "    lk_bad = 0\n",
        "\n",
        "    # timing\n",
        "    t_total0 = time.perf_counter()\n",
        "    t_read = 0.0\n",
        "    t_model = 0.0\n",
        "    t_lk = 0.0\n",
        "    t_overlay = 0.0\n",
        "    t_misc = 0.0\n",
        "    t_save = 0.0\n",
        "    t_roi = 0.0  # ROI crop/uncrop bookkeeping\n",
        "\n",
        "    if DEVICE == \"cuda\":\n",
        "        torch.cuda.empty_cache()\n",
        "        torch.cuda.synchronize()\n",
        "\n",
        "    # -------------------------------------------------------\n",
        "    # ROI helpers (FIXED SIZE square ROI)\n",
        "    # -------------------------------------------------------\n",
        "    # ROI side is derived from max_internal_size for convenience:\n",
        "    # max_internal_size=320 => roi_side ~ 640 (you can tune this factor)\n",
        "    ROI_FACTOR = 2.0\n",
        "    roi_side = int(max(256, min(min(w, h), min(1024, round(max_internal_size * ROI_FACTOR)))))\n",
        "    if roi_side > min(w, h):\n",
        "        roi_side = min(w, h)\n",
        "\n",
        "    def _bbox_from_mask(mask01):\n",
        "        ys, xs = np.where(mask01 > 0)\n",
        "        if ys.size == 0:\n",
        "            return None\n",
        "        x0, x1 = int(xs.min()), int(xs.max())\n",
        "        y0, y1 = int(ys.min()), int(ys.max())\n",
        "        return x0, y0, x1, y1\n",
        "\n",
        "    def _center_from_mask(mask01, fallback_cx, fallback_cy):\n",
        "        bb = _bbox_from_mask(mask01)\n",
        "        if bb is None:\n",
        "            return fallback_cx, fallback_cy\n",
        "        x0, y0, x1, y1 = bb\n",
        "        cx = 0.5 * (x0 + x1)\n",
        "        cy = 0.5 * (y0 + y1)\n",
        "        return cx, cy\n",
        "\n",
        "    def _roi_from_center(cx, cy):\n",
        "        # clamp ROI so it's always fully inside the frame (constant roi_side => constant CUTIE input size)\n",
        "        x0 = int(round(cx - roi_side / 2))\n",
        "        y0 = int(round(cy - roi_side / 2))\n",
        "        x0 = max(0, min(x0, w - roi_side))\n",
        "        y0 = max(0, min(y0, h - roi_side))\n",
        "        return x0, y0, x0 + roi_side, y0 + roi_side\n",
        "\n",
        "    def _crop_roi(frame_bgr, roi):\n",
        "        x0, y0, x1, y1 = roi\n",
        "        return frame_bgr[y0:y1, x0:x1]\n",
        "\n",
        "    def _place_roi_mask_to_full(mask_roi01, roi):\n",
        "        # mask_roi01: roi_side x roi_side\n",
        "        x0, y0, x1, y1 = roi\n",
        "        full = np.zeros((h, w), dtype=np.uint8)\n",
        "        full[y0:y1, x0:x1] = mask_roi01.astype(np.uint8)\n",
        "        return full\n",
        "\n",
        "    # initial ROI center from user mask\n",
        "    cx0, cy0 = _center_from_mask(mask_index, w / 2, h / 2)\n",
        "    roi = _roi_from_center(cx0, cy0)\n",
        "\n",
        "    # -------------------------------------------------------\n",
        "    # helper: LK warp in a WINDOW around mask (big speed-up)\n",
        "    # -------------------------------------------------------\n",
        "    def _compose_affine_with_crop(M, x0, y0):\n",
        "        # M maps (prev_crop) -> (curr_crop)\n",
        "        # full mapping: p_full -> p_full':\n",
        "        # p' = M*(p - t) + t, where t=(x0,y0)\n",
        "        a, b, c = float(M[0, 0]), float(M[0, 1]), float(M[0, 2])\n",
        "        d, e, f = float(M[1, 0]), float(M[1, 1]), float(M[1, 2])\n",
        "        tx, ty = float(x0), float(y0)\n",
        "        c2 = c + tx - a * tx - b * ty\n",
        "        f2 = f + ty - d * tx - e * ty\n",
        "        return np.array([[a, b, c2], [d, e, f2]], dtype=np.float32)\n",
        "\n",
        "    def _estimate_affine_lk_safe(prev_bgr, curr_bgr, prev_mask01):\n",
        "        # you may have already upgraded _estimate_affine_lk signature;\n",
        "        # this wrapper won't crash if it's still the old one.\n",
        "        try:\n",
        "            return _estimate_affine_lk(\n",
        "                prev_bgr, curr_bgr, prev_mask01,\n",
        "                max_corners=lk_corners,\n",
        "                lk_scale=0.33,\n",
        "                win_size=21,\n",
        "                max_level=3\n",
        "            )\n",
        "        except TypeError:\n",
        "            return _estimate_affine_lk(\n",
        "                prev_bgr, curr_bgr, prev_mask01,\n",
        "                max_corners=lk_corners\n",
        "            )\n",
        "\n",
        "    def warp_mask_lk(prev_frame_bgr, curr_frame_bgr, prev_mask01):\n",
        "        nonlocal lk_pairs, lk_bad, t_lk, t_misc\n",
        "\n",
        "        # if mask empty => nothing to track\n",
        "        bb = _bbox_from_mask(prev_mask01)\n",
        "        if bb is None:\n",
        "            lk_bad += 1\n",
        "            return prev_mask01\n",
        "\n",
        "        # window around mask bbox\n",
        "        x0, y0, x1, y1 = bb\n",
        "\n",
        "        # pad window (tune this)\n",
        "        PAD = 64\n",
        "        wx0 = max(0, x0 - PAD)\n",
        "        wy0 = max(0, y0 - PAD)\n",
        "        wx1 = min(w, x1 + PAD)\n",
        "        wy1 = min(h, y1 + PAD)\n",
        "\n",
        "        # ensure window has some size\n",
        "        if (wx1 - wx0) < 64 or (wy1 - wy0) < 64:\n",
        "            # expand minimally\n",
        "            wx0 = max(0, int((x0 + x1) / 2 - 64))\n",
        "            wy0 = max(0, int((y0 + y1) / 2 - 64))\n",
        "            wx1 = min(w, wx0 + 128)\n",
        "            wy1 = min(h, wy0 + 128)\n",
        "\n",
        "        prev_crop = prev_frame_bgr[wy0:wy1, wx0:wx1]\n",
        "        curr_crop = curr_frame_bgr[wy0:wy1, wx0:wx1]\n",
        "        mask_crop = prev_mask01[wy0:wy1, wx0:wx1]\n",
        "\n",
        "        t0 = time.perf_counter()\n",
        "        M, inlier_ratio, n_good = _estimate_affine_lk_safe(prev_crop, curr_crop, mask_crop)\n",
        "        t_lk += (time.perf_counter() - t0)\n",
        "        lk_pairs += 1\n",
        "\n",
        "        if (M is None) or (inlier_ratio < lk_inlier) or (n_good < 8):\n",
        "            lk_bad += 1\n",
        "            return prev_mask01\n",
        "\n",
        "        t0 = time.perf_counter()\n",
        "        M_full = _compose_affine_with_crop(M, wx0, wy0)\n",
        "        out = _warp_mask_affine(prev_mask01, M_full, w, h).astype(np.uint8)\n",
        "        t_misc += (time.perf_counter() - t0)\n",
        "        return out\n",
        "\n",
        "    # -------------------------------------------------------\n",
        "    # 1) read first frame + init CUTIE with user mask (ON ROI)\n",
        "    # -------------------------------------------------------\n",
        "    processed = 0\n",
        "\n",
        "    t0 = time.perf_counter()\n",
        "    ok, frame0 = cap.read()\n",
        "    t_read += (time.perf_counter() - t0)\n",
        "    if (not ok) or frame0 is None:\n",
        "        cap.release()\n",
        "        raise gr.Error(\"Failed to read the start frame.\")\n",
        "\n",
        "    # crop ROI for CUTIE init\n",
        "    t0 = time.perf_counter()\n",
        "    frame0_roi = _crop_roi(frame0, roi)\n",
        "    mask0_roi = _crop_roi(mask_index, roi)\n",
        "    t_roi += (time.perf_counter() - t0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        amp_device = \"cuda\" if DEVICE == \"cuda\" else \"cpu\"\n",
        "        with torch.amp.autocast(device_type=amp_device, enabled=(DEVICE == \"cuda\")):\n",
        "            t0 = time.perf_counter()\n",
        "            frame0_t = image_to_torch(frame0_roi, device=DEVICE)\n",
        "            mask_torch = index_numpy_to_one_hot_torch(mask0_roi, 2).to(DEVICE)\n",
        "            pred0 = processor.step(frame0_t, mask_torch[1:], idx_mask=False)\n",
        "            if DEVICE == \"cuda\":\n",
        "                torch.cuda.synchronize()\n",
        "            t_model += (time.perf_counter() - t0)\n",
        "            model_calls += 1\n",
        "\n",
        "    t0 = time.perf_counter()\n",
        "    anchor_mask_roi = torch_prob_to_numpy_mask(pred0).astype(np.uint8)  # roi_side x roi_side\n",
        "    anchor_mask = _place_roi_mask_to_full(anchor_mask_roi, roi)         # full HxW\n",
        "    anchor_frame = frame0\n",
        "    t_misc += (time.perf_counter() - t0)\n",
        "\n",
        "    # update ROI center based on anchor_mask (keep ROI following)\n",
        "    t0 = time.perf_counter()\n",
        "    cx, cy = _center_from_mask(anchor_mask, cx0, cy0)\n",
        "    roi = _roi_from_center(cx, cy)\n",
        "    t_roi += (time.perf_counter() - t0)\n",
        "\n",
        "    t0 = time.perf_counter()\n",
        "    overlay_frames_bgr.append(\n",
        "        overlay_fast_bgr(anchor_frame, anchor_mask, alpha=0.45, draw_outline=True)\n",
        "    )\n",
        "    t_overlay += (time.perf_counter() - t0)\n",
        "    processed += 1\n",
        "\n",
        "    # -------------------------------------------------------\n",
        "    # 2) main loop by segments: anchor -> next_anchor (K frames ahead)\n",
        "    # -------------------------------------------------------\n",
        "    with torch.no_grad():\n",
        "        amp_device = \"cuda\" if DEVICE == \"cuda\" else \"cpu\"\n",
        "        with torch.amp.autocast(device_type=amp_device, enabled=(DEVICE == \"cuda\")):\n",
        "\n",
        "            while processed < frames_to_propagate:\n",
        "                seg_k = min(K, frames_to_propagate - processed)\n",
        "                if seg_k <= 0:\n",
        "                    break\n",
        "\n",
        "                # read seg_k frames\n",
        "                seg_frames = []\n",
        "                for _ in range(seg_k):\n",
        "                    t0 = time.perf_counter()\n",
        "                    ok, fr = cap.read()\n",
        "                    t_read += (time.perf_counter() - t0)\n",
        "                    if (not ok) or fr is None:\n",
        "                        break\n",
        "                    seg_frames.append(fr)\n",
        "                if len(seg_frames) == 0:\n",
        "                    break\n",
        "\n",
        "                next_anchor_frame = seg_frames[-1]\n",
        "\n",
        "                # ---- run CUTIE on next anchor (ON ROI), independent anchor (no reinject) ----\n",
        "                t0 = time.perf_counter()\n",
        "                next_roi = roi\n",
        "                next_anchor_roi = _crop_roi(next_anchor_frame, next_roi)\n",
        "                t_roi += (time.perf_counter() - t0)\n",
        "\n",
        "                t0 = time.perf_counter()\n",
        "                fr_t = image_to_torch(next_anchor_roi, device=DEVICE)\n",
        "                pred_anchor = processor.step(fr_t)\n",
        "                if DEVICE == \"cuda\":\n",
        "                    torch.cuda.synchronize()\n",
        "                t_model += (time.perf_counter() - t0)\n",
        "                model_calls += 1\n",
        "\n",
        "                t0 = time.perf_counter()\n",
        "                next_anchor_mask_roi = torch_prob_to_numpy_mask(pred_anchor).astype(np.uint8)\n",
        "                next_anchor_mask = _place_roi_mask_to_full(next_anchor_mask_roi, next_roi)\n",
        "                t_misc += (time.perf_counter() - t0)\n",
        "\n",
        "                # update ROI based on next anchor mask (follow the object)\n",
        "                t0 = time.perf_counter()\n",
        "                cx, cy = _center_from_mask(next_anchor_mask, cx, cy)\n",
        "                roi = _roi_from_center(cx, cy)\n",
        "                t_roi += (time.perf_counter() - t0)\n",
        "\n",
        "                mid_count = len(seg_frames) - 1\n",
        "\n",
        "                # ---- no intermediate => just append anchor ----\n",
        "                if mid_count <= 0:\n",
        "                    t0 = time.perf_counter()\n",
        "                    overlay_frames_bgr.append(\n",
        "                        overlay_fast_bgr(next_anchor_frame, next_anchor_mask, alpha=0.45, draw_outline=True)\n",
        "                    )\n",
        "                    t_overlay += (time.perf_counter() - t0)\n",
        "                    processed += 1\n",
        "                    anchor_frame = next_anchor_frame\n",
        "                    anchor_mask = next_anchor_mask\n",
        "                    continue\n",
        "\n",
        "                # -------------------------------------------------------\n",
        "                # forward warps: anchor -> mid frames\n",
        "                # -------------------------------------------------------\n",
        "                fwd_masks = [None] * mid_count\n",
        "                prev_f = anchor_frame\n",
        "                prev_m = anchor_mask\n",
        "                for i in range(mid_count):\n",
        "                    cur_f = seg_frames[i]\n",
        "                    cur_m = warp_mask_lk(prev_f, cur_f, prev_m)\n",
        "                    fwd_masks[i] = cur_m\n",
        "                    prev_f = cur_f\n",
        "                    prev_m = cur_m\n",
        "\n",
        "                # -------------------------------------------------------\n",
        "                # backward warps: next_anchor -> mid frames (reverse)\n",
        "                # -------------------------------------------------------\n",
        "                bwd_masks = [None] * mid_count\n",
        "                prev_f = next_anchor_frame\n",
        "                prev_m = next_anchor_mask\n",
        "                for i in range(mid_count - 1, -1, -1):\n",
        "                    cur_f = seg_frames[i]\n",
        "                    cur_m = warp_mask_lk(prev_f, cur_f, prev_m)\n",
        "                    bwd_masks[i] = cur_m\n",
        "                    prev_f = cur_f\n",
        "                    prev_m = cur_m\n",
        "\n",
        "                # -------------------------------------------------------\n",
        "                # blend masks + overlay mid frames\n",
        "                # -------------------------------------------------------\n",
        "                for i in range(mid_count):\n",
        "                    t0 = time.perf_counter()\n",
        "                    wgt = float(i + 1) / float(len(seg_frames))  # (0,1)\n",
        "                    fm = fwd_masks[i].astype(np.float32)\n",
        "                    bm = bwd_masks[i].astype(np.float32)\n",
        "                    blended = ((1.0 - wgt) * fm + wgt * bm) >= 0.5\n",
        "                    pred_index = blended.astype(np.uint8)\n",
        "                    t_misc += (time.perf_counter() - t0)\n",
        "\n",
        "                    t0 = time.perf_counter()\n",
        "                    overlay_frames_bgr.append(\n",
        "                        overlay_fast_bgr(seg_frames[i], pred_index, alpha=0.45, draw_outline=True)\n",
        "                    )\n",
        "                    t_overlay += (time.perf_counter() - t0)\n",
        "\n",
        "                    processed += 1\n",
        "                    if processed >= frames_to_propagate:\n",
        "                        break\n",
        "\n",
        "                if processed >= frames_to_propagate:\n",
        "                    break\n",
        "\n",
        "                # append next anchor frame\n",
        "                t0 = time.perf_counter()\n",
        "                overlay_frames_bgr.append(\n",
        "                    overlay_fast_bgr(next_anchor_frame, next_anchor_mask, alpha=0.45, draw_outline=True)\n",
        "                )\n",
        "                t_overlay += (time.perf_counter() - t0)\n",
        "                processed += 1\n",
        "\n",
        "                # slide anchors\n",
        "                anchor_frame = next_anchor_frame\n",
        "                anchor_mask = next_anchor_mask\n",
        "\n",
        "    cap.release()\n",
        "\n",
        "    if len(overlay_frames_bgr) == 0:\n",
        "        raise gr.Error(\"No frames processed. Check video path / start_frame.\")\n",
        "\n",
        "    # ---- save video time ----\n",
        "    t0 = time.perf_counter()\n",
        "    overlay_mp4 = os.path.join(OUT_DIR, f\"overlay_{int(time.time()*1000)}.mp4\")\n",
        "    _save_overlay_video(overlay_frames_bgr, fps, overlay_mp4)\n",
        "    t_save = time.perf_counter() - t0\n",
        "\n",
        "    t_total = time.perf_counter() - t_total0\n",
        "\n",
        "    processed = len(overlay_frames_bgr)\n",
        "    video_seconds = processed / max(1e-6, fps)\n",
        "    avg_gen_fps = processed / max(1e-6, t_total)\n",
        "    slow_x = (t_total / max(1e-6, video_seconds))\n",
        "\n",
        "    per = lambda x: (x / max(1, processed))\n",
        "    status = (\n",
        "        f\"Done | processed={processed} frames | video_len={video_seconds:.2f}s @ {fps:.2f}fps\\n\"\n",
        "        f\"TOTAL: {t_total:.3f}s | avg_gen_fps={avg_gen_fps:.2f} | slow_x={slow_x:.2f}x (vs realtime)\\n\"\n",
        "        f\"Breakdown (total / per-frame):\\n\"\n",
        "        f\"  read:    {t_read:.3f}s  / {per(t_read)*1000:.2f} ms\\n\"\n",
        "        f\"  ROI:     {t_roi:.3f}s   / {per(t_roi)*1000:.2f} ms   (roi_side={roi_side})\\n\"\n",
        "        f\"  CUTIE:   {t_model:.3f}s / {per(t_model)*1000:.2f} ms   (model_calls={model_calls})\\n\"\n",
        "        f\"  LK:      {t_lk:.3f}s    / {per(t_lk)*1000:.2f} ms      (lk_pairs={lk_pairs}, lk_bad={lk_bad})\\n\"\n",
        "        f\"  overlay: {t_overlay:.3f}s / {per(t_overlay)*1000:.2f} ms\\n\"\n",
        "        f\"  misc:    {t_misc:.3f}s / {per(t_misc)*1000:.2f} ms\\n\"\n",
        "        f\"  save_mp4:{t_save:.3f}s  / {per(t_save)*1000:.2f} ms\\n\"\n",
        "        f\"Params: max_internal_size={max_internal_size} | K(lk_every)={K} | lk_corners={lk_corners} | lk_inlier={lk_inlier}\\n\"\n",
        "        f\"Video: {os.path.basename(vp)} size={w}x{h} start={start_frame_idx}\"\n",
        "    )\n",
        "\n",
        "    return overlay_mp4, status\n",
        "\n",
        "\n",
        "def run_track_safe(video_path_str, start_frame_idx, editor_value, frames_to_propagate, max_internal_size,\n",
        "                   lk_every, lk_corners, lk_inlier):\n",
        "    try:\n",
        "        return run_track(video_path_str, start_frame_idx, editor_value, frames_to_propagate, max_internal_size,\n",
        "                         lk_every, lk_corners, lk_inlier)\n",
        "\n",
        "    except Exception as e:\n",
        "        traceback.print_exc()\n",
        "        raise gr.Error(str(e))\n",
        "\n",
        "\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## CUTIE (Preview video in Gradio + draw mask on a selected frame)\")\n",
        "\n",
        "    # <<< changed: file picker instead of hardcoded textbox/path\n",
        "    video_file = gr.File(\n",
        "        label=\"Select / Upload video\",\n",
        "        file_types=[\".mp4\", \".avi\", \".mov\", \".mkv\"],\n",
        "        type=\"filepath\",\n",
        "    )\n",
        "\n",
        "    with gr.Row():\n",
        "        load_btn = gr.Button(\"Load video\")\n",
        "        info = gr.Textbox(label=\"Info\", interactive=False)\n",
        "\n",
        "    with gr.Row():\n",
        "        orig_video = gr.Video(label=\"Original Video (preview here)\")\n",
        "        overlay_video = gr.Video(label=\"Overlay Video (result preview)\")\n",
        "\n",
        "    gr.Markdown(\"### 1) Use the video player to preview (pause/seek).  2) Choose a frame index below to annotate (Gradio can't read the paused timestamp).\")\n",
        "\n",
        "    with gr.Row():\n",
        "        frame_idx = gr.Slider(0, 0, value=0, step=1, label=\"Frame index to annotate (acts like pause point)\")\n",
        "        show_btn = gr.Button(\"Load this frame for annotation\")\n",
        "\n",
        "    with gr.Row():\n",
        "        frame_view = gr.Image(label=\"Selected Frame\", type=\"pil\", interactive=False)\n",
        "        mask_editor = gr.ImageEditor(label=\"Paint directly ON the frame (your strokes define the mask)\", type=\"pil\")\n",
        "\n",
        "    frames_to_prop = gr.Slider(1, 1, value=200, step=1, label=\"frames_to_propagate (auto max = remaining frames)\")\n",
        "\n",
        "    # <<< changed: initial value to 400\n",
        "    max_internal_size = gr.Slider(\n",
        "        256, 1024, value=400, step=32,\n",
        "        label=\"max_internal_size (max internal side; smaller=faster, lower quality)\"\n",
        "    )\n",
        "\n",
        "    # <<< changed: remove LK controls from UI (keep functions; just don't expose controls)\n",
        "    # We'll feed constants into the backend so LK isn't used (K=1 => pure CUTIE)\n",
        "    lk_every_state = gr.State(1)\n",
        "    lk_corners_state = gr.State(400)\n",
        "    lk_inlier_state = gr.State(0.25)\n",
        "\n",
        "    run_btn = gr.Button(\"Run CUTIE from this frame\")\n",
        "    status = gr.Textbox(label=\"Status\", interactive=False)\n",
        "\n",
        "    load_btn.click(\n",
        "        load_video,\n",
        "        inputs=[video_file],\n",
        "        outputs=[orig_video, frame_view, mask_editor, frame_idx, frames_to_prop, max_internal_size, info],\n",
        "        queue=False\n",
        "    )\n",
        "\n",
        "    show_btn.click(\n",
        "        show_frame,\n",
        "        inputs=[video_file, frame_idx],\n",
        "        outputs=[frame_view, mask_editor, frames_to_prop],\n",
        "        queue=False\n",
        "    )\n",
        "\n",
        "    run_btn.click(\n",
        "        run_track_safe,\n",
        "        inputs=[video_file, frame_idx, mask_editor, frames_to_prop, max_internal_size,\n",
        "                lk_every_state, lk_corners_state, lk_inlier_state],\n",
        "        outputs=[overlay_video, status],\n",
        "        queue=True\n",
        "    )\n",
        "\n",
        "demo.launch(allowed_paths=[OUT_DIR], inbrowser=True, debug=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_fhZ9bYyi32",
        "outputId": "b19b022c-fcf8-428b-c9eb-ffedcedb2992"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "grep: /content/Cutie/cutie/inference/__pycache__/inference_core.cpython-312.pyc: binary file matches\n",
            "/content/Cutie/cutie/config/eval_config.yaml:23:max_internal_size: -1\n",
            "/content/Cutie/cutie/config/gui_config.yaml:17:max_internal_size: 480\n",
            "/content/Cutie/cutie/config/video_config.yaml:20:max_internal_size: 480\n",
            "/content/Cutie/cutie/inference/inference_core.py:31:        self.max_internal_size = cfg.max_internal_size\n",
            "/content/Cutie/cutie/inference/inference_core.py:208:        if self.max_internal_size > 0:\n",
            "/content/Cutie/cutie/inference/inference_core.py:211:            if min_side > self.max_internal_size:\n",
            "/content/Cutie/cutie/inference/inference_core.py:213:                new_h = int(h / min_side * self.max_internal_size)\n",
            "/content/Cutie/cutie/inference/inference_core.py:214:                new_w = int(w / min_side * self.max_internal_size)\n"
          ]
        }
      ],
      "source": [
        "!grep -R \"max_internal_size\" -n /content/Cutie/cutie | head\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "7zCVtDJcA-b1"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}